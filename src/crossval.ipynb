{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "944bf37f-db32-4986-bb58-7a14f5225fe7",
   "metadata": {},
   "source": [
    "# Перекрёстная валидация\n",
    "\n",
    "В этой тетради мы изучим метод кросс-валидации для оценки производительности \n",
    "моделей машинного обучения и понять его преимущества по сравнению  \n",
    "простым разделением данных на обучающий и тестовый наборы.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194d9257-a29c-4fa3-bb2a-56ddf481bc9e",
   "metadata": {},
   "source": [
    "## Знакомство с кросс-валидацией\n",
    "\n",
    "Рассмотрим, что из себя вообще представляет кросс-валидация в общих чертах, а затем рассмотрим конкретные интерфейсы, поставляемые фреймворком Scikit-Learn.\n",
    "\n",
    "Перекрестная валидация - это статистический метод, используемый для оценки и сравнения моделей машинного обучения путем разделения доступных данных на два сегмента: один для обучения модели, а другой для проверки модели. Цель перекрестной проверки - оценить, насколько хорошо модель обобщается на новых данных, и выявить потенциальные проблемы, такие как переобучение.\n",
    "\n",
    "Можно выделить два типа перекрестной проверки:\n",
    "* Исчерпывающая перекрестная проверка: Этот метод изучает и тестирует все возможные способы разделения исходной выборки на обучающий и проверочный набор.\n",
    "* K-кратная перекрестная проверка: При k-кратной перекрестной проверке исходная выборка случайным образом разбивается на $k$ подвыборок одинакового размера. Из $k$ подвыборок одна подвыборка сохраняется в качестве проверочных данных для тестирования модели, а остальные $k - 1$ подвыборок используются в качестве обучающих данных. Затем процесс перекрестной проверки повторяется $k$ раз, причем каждая из $k$ подвыборок используется ровно один раз в качестве данных для проверки.\n",
    "\n",
    "Таким образом, перекрестная проверка является ценным методом оценки моделей машинного обучения, гарантирующим, что модель хорошо обобщает, а не просто запоминает обучающие данные. Это надежный способ оценить производительность модели на данных, которые модель до этого не видела, и широко используется в машинном обучении.\n",
    "\n",
    "Перейдём теперь к конкретным методам, которые мы можем применить к нашим данным.\n",
    "\n",
    "### K-Fold\n",
    "\n",
    "K-Fold (`KFold`) делит все выборки на $k$ групп выборок, называемые складками (если $k = n$, это эквивалентно стратегии исключения одной выборки), одинакового размера (если это возможно). Функция прогнозирования изучается с $k - 1$ помощью складок, а оставшаяся часть используется для тестирования.\n",
    "\n",
    "### Stratified K-Fold\n",
    "\n",
    "Стратифицированный K-Fold - это вариация `KFold`, которая возвращает стратифицированные складки: каждый набор содержит примерно такой же процент образцов каждого целевого класса, как и полный набор.\n",
    "\n",
    "### Stratified Shuffle Split\n",
    "\n",
    "Этот метод суть вариация [`ShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit), которая возвращает стратифицированные разбиения, т.е. создает разбиения, сохраняя тот же процент для каждого целевого класса, что и в полном наборе.\n",
    "\n",
    "Подробнее об этих и других методах кросс-валидации можно почитать [здесь](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-and-model-selection).\n",
    "\n",
    "Приступим теперь к практическим примерам.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bf2dd-da41-4511-bce9-c2ee76405587",
   "metadata": {},
   "source": [
    "## Практические примеры\n",
    "\n",
    "Посмотрим сейчас, как можно применять вышеописанные методы.\n",
    "\n",
    "Однако сначала, как обычно, выполним импорты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73ff20ae-7c6e-4fbe-8408-20887e71013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from numpy import ndarray\n",
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    KFold,\n",
    "    StratifiedKFold,\n",
    "    StratifiedShuffleSplit,\n",
    "    train_test_split,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cf3ab9-41b2-4b22-9c18-a7c43154a4f9",
   "metadata": {},
   "source": [
    "А так же выполним загрузку данных. В этот раз воспользуемся набором данных ирисов Фишера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "def2dc8f-ef85-492d-88cc-bb905c2473e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = read_csv(\"../datasets/iris.csv\")\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db60e17-e1c7-4fac-874d-c1a8b1c721ac",
   "metadata": {},
   "source": [
    "Отделим независимые пременные от целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63d45cb3-7091-4043-99f0-cb91c2c6e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_iris, y_iris = iris.iloc[:, 1:-1], iris.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058c7f7b-8767-4d59-ae1c-bb50a8a8a0c5",
   "metadata": {},
   "source": [
    "### K-Fold\n",
    "\n",
    "Первым делом рассмотрим процесс работы `KFold`. Предварительно инициализируем модель Случайного леса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549fd1cf-452c-4a4d-b621-66f892240832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold accuracy: 0.96 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "def rate_accuracy(\n",
    "    x: ndarray,\n",
    "    y: ndarray,\n",
    "    title: str,\n",
    "    *,\n",
    "    validator,\n",
    "    shuffle: Optional[bool] = None,\n",
    "    n_splits: int,\n",
    ") -> None:\n",
    "    random_forest = RandomForestClassifier()\n",
    "    validator_initialized = validator(n_splits=n_splits)\n",
    "    if shuffle:\n",
    "        validator_initialized = validator(n_splits=n_splits, shuffle=True, random_state=52)\n",
    "    kfold_score = cross_val_score(\n",
    "        random_forest, x, y,\n",
    "        cv=validator_initialized,\n",
    "        scoring=\"accuracy\",\n",
    "    )\n",
    "\n",
    "    print(\"%s: %0.2f (+/- %0.2f)\" % (title, kfold_score.mean(), kfold_score.std() * 2))\n",
    "\n",
    "\n",
    "rate_accuracy(x_iris, y_iris, \"K-Fold accuracy\", validator=KFold, shuffle=True, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1553c33b-109c-4e25-85e8-c12ccbe9c52e",
   "metadata": {},
   "source": [
    "Посмотрим сейчас, как на точность повлияет количество разбиений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6720f03-ca37-420b-b1f6-580192b13788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold accuracy with 15 splits: 0.95 (+/- 0.12)\n",
      "K-Fold accuracy with 10 splits: 0.95 (+/- 0.09)\n",
      "K-Fold accuracy with 3 splits: 0.94 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"K-Fold accuracy with 15 splits\",\n",
    "    shuffle=True, validator=KFold, n_splits=15,\n",
    ")\n",
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"K-Fold accuracy with 10 splits\",\n",
    "    shuffle=True, validator=KFold, n_splits=10,\n",
    ")\n",
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"K-Fold accuracy with 3 splits\",\n",
    "    shuffle=True, validator=KFold, n_splits=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24bf898-83de-4dcc-9fb4-7101d7035ebe",
   "metadata": {},
   "source": [
    "Как видим, точность выше, когда разбиений больше, однако прямо пропорционально количеству разбиений растёт и отклонение. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e5cf28-357b-4213-a061-a232d6779717",
   "metadata": {},
   "source": [
    "### Stratified K-Fold\n",
    "\n",
    "Приступим к `StratifiedKFold` и выясним, сильно ли нам поможет стратификация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9fb26ad-870f-4dd8-8303-5b3c5749ee4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold accuracy with 15 splits: 0.95 (+/- 0.14)\n",
      "Stratified K-Fold accuracy with 10 splits: 0.96 (+/- 0.14)\n",
      "Stratified K-Fold accuracy with 3 splits: 0.94 (+/- 0.07)\n"
     ]
    }
   ],
   "source": [
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"Stratified K-Fold accuracy with 15 splits\",\n",
    "    shuffle=True, validator=StratifiedKFold, n_splits=15,\n",
    ")\n",
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"Stratified K-Fold accuracy with 10 splits\",\n",
    "    shuffle=True, validator=StratifiedKFold, n_splits=10,\n",
    ")\n",
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"Stratified K-Fold accuracy with 3 splits\",\n",
    "    shuffle=True, validator=StratifiedKFold, n_splits=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfb6b62-2f9e-4d0f-b962-0ba4c8b702d3",
   "metadata": {},
   "source": [
    "В общем, точность не изменилась, но отклонение стало меньше при пятнадцати разбиениях."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee799f-cdb4-4254-90b1-c6bee5f6ea0e",
   "metadata": {},
   "source": [
    "### Stratified Shuffle Split\n",
    "\n",
    "И, наконец, проанализируем результаты, которые нам выдаст `StratifiedShuffleSplit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84b3548e-fd03-4727-aee7-01fd9493ea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified Shuffle Split accuracy with 15 splits: 0.94 (+/- 0.11)\n",
      "Stratified Shuffle Split accuracy with 10 splits: 0.95 (+/- 0.12)\n",
      "Stratified Shuffle Split accuracy with 3 splits: 1.00 (+/- 0.00)\n"
     ]
    }
   ],
   "source": [
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"Stratified Shuffle Split accuracy with 15 splits\",\n",
    "    validator=StratifiedShuffleSplit, n_splits=15,\n",
    ")\n",
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"Stratified Shuffle Split accuracy with 10 splits\",\n",
    "    validator=StratifiedShuffleSplit, n_splits=10,\n",
    ")\n",
    "rate_accuracy(\n",
    "    x_iris, y_iris, \"Stratified Shuffle Split accuracy with 3 splits\",\n",
    "    validator=StratifiedShuffleSplit, n_splits=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923e336-17f4-45e8-9c27-2b09131f9f35",
   "metadata": {},
   "source": [
    "Интересно. В этот раз отклонение не так велико при большем количестве разбиений, однако становится намного сильнее при меньшем их количестве по сравнению с другмими методами.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a518dc-00a2-461a-b5bb-f4cfcd333488",
   "metadata": {},
   "source": [
    "## Оптимизация моделей\n",
    "\n",
    "Теперь, когда мы уже знакомы с некоторыми методами кросс-валидации, попробуем оптимизировать гиперпараметры модели Случайного леса, которой мы пользовались выше. Для этого нам пригодится класс [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV). Однако сперва нужно разбить данные на тренировочную и обучающую выборки. Масштабирование делать необязательно, так как деревья решений склонны показывать лучший результат на сырых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f7b50f5-ddad-4b77-84b7-b025a95e9ca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': 'gini',\n",
       " 'max_depth': 100,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_iris, y_iris, test_size=0.3, random_state=52)\n",
    "# Defining the parameters variations\n",
    "parameters_grid = {\n",
    "    \"n_estimators\": (10, 100, 1000),\n",
    "    \"criterion\": (\"gini\", \"entropy\", \"log_loss\"),\n",
    "    \"max_depth\": (10, 100, None),\n",
    "    \"min_samples_split\": (2, 4, 6),\n",
    "    \"min_samples_leaf\": (1, 2, 3),\n",
    "    \"min_weight_fraction_leaf\": (0.1, 0.01, 0.0),\n",
    "}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(), param_grid=parameters_grid)\n",
    "\n",
    "# Fitting the optimizer with the training data\n",
    "grid_search.fit(x_train, y_train)\n",
    "# Obtaining the best parameters for the model\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11fa1d2-99c2-4a9a-bbbd-8d770d1f75d7",
   "metadata": {},
   "source": [
    "В результате мы получили параметры для модели, которые гарантируют следующую точность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "520334cb-8b4b-43ec-81e1-5676a4e00444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d52106-02e6-467c-aad0-1de5e2511202",
   "metadata": {},
   "source": [
    "Очень даже неплохо.\n",
    "\n",
    "Подведём итоги.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d799acd3",
   "metadata": {},
   "source": [
    "# Заключение\n",
    "\n",
    "В этой тетради мы научились пользоваться алгоритмами перекрёстной провекрки. Выполнив код, демонстрирующий работу различных алгоритмов перекрёстной проверки в «игрушеченой» среде, мы увидели значимость их влада в точность моделей даже на небольших наборах данных.\n",
    "\n",
    "Стоит ещё раз отметить, что перекрестная проверка является ценным методом оценки моделей машинного обучения, гарантирующим, что модель хорошо обобщает, а не просто запоминает обучающие данные. Это надежный способ оценить производительность модели на данных, которые модель до этого не видела, и широко используется в машинном обучении."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
